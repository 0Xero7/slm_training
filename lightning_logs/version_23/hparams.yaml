d_model: 512
dropout: 0.10661204600851977
ff_hidden: 2048
lr: 2.1072829766274626e-05
max_seq_len: 128
num_epochs: 20
num_layers: 12
use_experimental: false
vocab_size: 50258
weight_decay: 0.006189637912201511
